{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aa/hossay/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from config import FLAGS\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _linear(_input, output_size, scope, use_bias=True):\n",
    "    if len(_input.get_shape().as_list())>3:\n",
    "        raise AssertionError('At most rank 3 tensor is supported!')\n",
    "    shape = _input.get_shape().as_list()\n",
    "    \n",
    "    _input = tf.reshape(_input, (-1,shape[-1]))\n",
    "    \n",
    "    with tf.variable_scope(scope):\n",
    "        W = tf.get_variable('W', [shape[-1], output_size], dtype='float32')\n",
    "        if use_bias:\n",
    "            B = tf.get_variable('B', [output_size])\n",
    "            res = tf.matmul(_input,W)+B\n",
    "        else:\n",
    "            res = tf.matmul(_input,W)\n",
    "    \n",
    "    return tf.reshape(res,(shape[:2] + [output_size])) if len(shape)==3 else res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = FLAGS.batch_size\n",
    "num_units = FLAGS.num_units\n",
    "num_layers = FLAGS.num_layers\n",
    "dim_emb = FLAGS.dim_emb\n",
    "attn_size =FLAGS.attn_size\n",
    "# these values will be changed to biggest bucket's length\n",
    "maxlen_src = 10\n",
    "maxlen_target = 10\n",
    "# vocabulary size\n",
    "src_vocab_size = target_vocab_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholders\n",
    "src = [ tf.placeholder('int32', [batch_size]) for _ in range(maxlen_src) ]\n",
    "target = [ tf.placeholder('int32', [batch_size]) for _ in range(maxlen_target) ]\n",
    "\n",
    "# Encoder & Decoder cell (if need dropout,,, add dropout!)\n",
    "encoder_cell = tf.nn.rnn_cell.LSTMCell(num_units=num_units)\n",
    "encoder_cell = tf.nn.rnn_cell.MultiRNNCell([encoder_cell]*num_layers)\n",
    "\n",
    "decoder_cell = tf.nn.rnn_cell.LSTMCell(num_units=num_units)\n",
    "decoder_cell = tf.nn.rnn_cell.MultiRNNCell([decoder_cell]*num_layers)\n",
    "\n",
    "# embedding layer(embedding for src sentence & target)\n",
    "src_embedding = tf.get_variable('src_embedding', [src_vocab_size,dim_emb], 'float32')\n",
    "target_embedding = tf.get_variable('target_embedding', [target_vocab_size,dim_emb], 'float32')\n",
    "\n",
    "src_embed = tf.nn.embedding_lookup(src_embedding, src)\n",
    "target_embed = tf.nn.embedding_lookup(target_embedding, target)\n",
    "\n",
    "# Encoder(can be bi-directional rnn)\n",
    "encoder_outputs, encoder_state = tf.nn.dynamic_rnn(cell=encoder_cell, inputs=_linear(src_embed, num_units, 'Encoder/input_projection'),\n",
    "                                                   time_major=True, scope='Encoder', dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "with tf.variable_scope('Decoder'):\n",
    "    decoder_state = encoder_state\n",
    "\n",
    "    for t in range(maxlen_target):\n",
    "        if t==0:\n",
    "            go_embed = tf.nn.embedding_lookup(target_embedding, tf.fill([batch_size],FLAGS.GO))\n",
    "            next_input = tf.concat([go_embed, tf.zeros([batch_size, attn_size], 'float32')], axis=1)\n",
    "        else:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        \n",
    "        # projection\n",
    "        decoder_output, decoder_state = decoder_cell(_linear(next_input, num_units, 'input_projection'), decoder_state)\n",
    "\n",
    "        # Attention block\n",
    "        # 1. attention weights\n",
    "\n",
    "        # target projections for comparison(num_units --> attn_size)\n",
    "        target_projections = [_linear(decoder_output,attn_size,'compare_target')]*maxlen_src\n",
    "        target_projections = tf.stack(target_projections)\n",
    "\n",
    "        # source projections for comparison(num_units --> attn_size)\n",
    "        src_projections = _linear(encoder_outputs,attn_size,'compare_src')\n",
    "\n",
    "        # attention weights(attention distribution)\n",
    "        attn_weights = tf.nn.softmax(tf.nn.tanh(target_projections+src_projections))\n",
    "        \n",
    "        # 2. context vector\n",
    "        ctx_vec = tf.reduce_sum(attn_weights*encoder_outputs, axis=0)\n",
    "\n",
    "        # 3. attention vector\n",
    "        concat = tf.concat([ctx_vec, decoder_output], axis=1)\n",
    "        attn_vec = tf.nn.tanh(_linear(concat,attn_size,'attn'))\n",
    "\n",
    "        cur_embed = target_embed[t,:]\n",
    "        next_input = tf.concat([cur_embed, attn_vec], axis=1)\n",
    "        #print next_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'src_embedding:0',\n",
       " u'target_embedding:0',\n",
       " u'Encoder/input_projection/W:0',\n",
       " u'Encoder/input_projection/B:0',\n",
       " u'Encoder/multi_rnn_cell/cell_0/lstm_cell/kernel:0',\n",
       " u'Encoder/multi_rnn_cell/cell_0/lstm_cell/bias:0',\n",
       " u'Decoder/input_projection/W:0',\n",
       " u'Decoder/input_projection/B:0',\n",
       " u'Decoder/multi_rnn_cell/cell_0/lstm_cell/kernel:0',\n",
       " u'Decoder/multi_rnn_cell/cell_0/lstm_cell/bias:0',\n",
       " u'Decoder/compare_target/W:0',\n",
       " u'Decoder/compare_target/B:0',\n",
       " u'Decoder/compare_src/W:0',\n",
       " u'Decoder/compare_src/B:0',\n",
       " u'Decoder/attn/W:0',\n",
       " u'Decoder/attn/B:0']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ v.name for v in tf.trainable_variables() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
